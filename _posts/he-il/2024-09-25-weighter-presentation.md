---
layout: post
title: הסבר למצגת "ממשקל" מ-DefenseML
date: 2024-09-25 13:00:00
description: הסבר מעמיק להרצאה שהעברתי בכנס DefenseML של MDLI על מחקר מרתק עם הכותרת "ממשקל".
tags: research
categories: professional
thumbnail: /assets/img/defenseml-banner.png
---

<br/>
<div class="row">
 <div class="col-sm mt-3 mt-md-0">
 {% include figure.liquid loading="eager" path="assets/img/defenseml/he-il/01.png" title="שקופית הפתיחה" class="img-fluid rounded z-depth-1" %}
 </div>
</div>
<div class="caption">
 צפו <a href="https://machinelearning.co.il/lp-events/defenseml/">בסרטון שלי מעביר את ההרצאה!</a> אתם יכולים גם לפתוח את <a href="https://docs.google.com/presentation/d/1QP9b4ywiy1CL_9DU-WOqo2rGDdN3GsB5Wu-hEX2_N6w/edit?usp=drivesdk">המצגת המקורית</a> :)
</div>

הכנס DefenseML היה מרתק ומשמעותי, היה לי התענוג להרצות לצד מרצים מוכשרים ועם מארגנים תותחים שהשקיעו בכנס שרמתו הייתה גבוהה מאוד.

לאחר ההרצאה יצא לי לדבר עם חלק מאורחי הכנס, קיבלתי הרבה מחמאות אבל גם היו ביקורות וקשיים.  
הביקורת הראשונה שאמרו לי היא ששקופית ה-LinkedIn הייתה רק בתחילת המצגת - לפני שידעו שאני שווה משהו.  
למזלי זו ביקורת שקל לתקן, הביקורת היותר כללית שלא נאמרה מפורשות אבל הייתה לי ברורה - היא שקשה מההרצאה להבין איך הדברים באמת עובדים.

זו ביקורת לה ציפיתי, ב-20 דקות אי אפשר לסכם את כל הפרטים של מחקר שלם ורחב, ניסיתי לתת טעימות, אינטואיציות, כיוונים, אבל לא יכלתי לתת הבנה.  
בפוסט הזה אני אנסה לענות על חלק מהשאלות ששאלו אותי, להבהיר נקודות שבלבלו חלק מהאנשים ולהרחיב על חלק מהרעיונות שהוצגו בהרצאה.

כדי להבין את הבלוג פוסט הזה אתם צריכים להכיר את ההרצאה עצמה, המארגנים האדיבים של הכנס העלו את [ההרצאה במלואה בערוץ ה-Youtube שלהם](https://youtu.be/wxMQJ3vXngg), אתם מוזמנים לראות אותה שם :)  
בנוסף אתם מוזמנים לעבור על [המצגת שלי](https://docs.google.com/presentation/d/1QP9b4ywiy1CL_9DU-WOqo2rGDdN3GsB5Wu-hEX2_N6w/edit?usp=drivesdk) בעצמכם ובקצב שלכם, בלי קשר להרצאה עצמה.

## שאלות ותשובות

1. **מה המודל שלכם מוציא כפלט?**  
   בעת אימון למודל יש ראש קלאסיפיקציה, כלומר הפלט שלו הוא N וקטורים של לוג'יטים בגודל של כמות ה-class-ים (כמות הדוברים ב-train-set, במקרה שלנו 856).  
   בעת inference אנחנו לא משתמשים בראש הקלאסיפיקציה, לכן במקום לקבל N וקטורים של לוג'יטים אנחנו מקבלים N וקטורים של Embeddings (במקרה שלנו 256 מימדים).

2. **מה המודל בכלל לומד אם "לייק" לא מייחד את הקובץ? מה ה-supervision פה?**  
   המודל לומד לייצר לכל קובץ סט Embeddings שייצג את ה"לייקים" שתויגו עליו.  
   כלומר - המודל לומד לייצר Embeddings דומים לקבצים עליהם יש את אותו ה"לייק", עצם זה שצריך להיות Embedding משותף זה ה-supervision.
3. דיברת על קלסטור
