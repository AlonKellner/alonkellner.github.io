---
layout: post
title: הסבר למצגת "ממשקל" מ-DefenseML
date: 2024-10-16 13:00:00
description: הסבר מעמיק להרצאה שהעברתי בכנס DefenseML של MDLI על מחקר מרתק עם הכותרת "ממשקל".
tags: research
categories: professional
thumbnail: /assets/img/defenseml-banner.png
---

<br/>
<div class="row">
 <div class="col-sm mt-3 mt-md-0">
 {% include figure.liquid loading="eager" path="assets/img/defenseml/he-il/01.png" title="שקופית הפתיחה" class="img-fluid rounded z-depth-1" %}
 </div>
</div>
<div class="caption">
 צפו <a href="https://machinelearning.co.il/lp-events/defenseml/">בסרטון שלי מעביר את ההרצאה!</a> אתם יכולים גם לפתוח את <a href="https://docs.google.com/presentation/d/1QP9b4ywiy1CL_9DU-WOqo2rGDdN3GsB5Wu-hEX2_N6w/edit?usp=drivesdk">המצגת המקורית</a> :)
</div>

הכנס DefenseML היה מרתק ומשמעותי, היה לי התענוג להרצות לצד מרצים מוכשרים ועם מארגנים תותחים שהשקיעו בכנס שרמתו הייתה גבוהה מאוד.

לאחר ההרצאה יצא לי לדבר עם חלק מאורחי הכנס, קיבלתי הרבה מחמאות אבל גם היו ביקורות וקשיים.  
הביקורת הראשונה שאמרו לי היא ששקופית ה-LinkedIn הייתה רק בתחילת המצגת - לפני שידעו שאני שווה משהו.  
למזלי זו ביקורת שקל לתקן, הביקורת היותר כללית שלא נאמרה מפורשות אבל הייתה לי ברורה - היא שקשה מההרצאה להבין איך הדברים באמת עובדים.

זו ביקורת לה ציפיתי, ב-20 דקות אי אפשר לסכם את כל הפרטים של מחקר שלם ורחב, ניסיתי לתת טעימות, אינטואיציות, כיוונים, אבל לא יכלתי לתת הבנה.  
בפוסט הזה אני אנסה לענות על חלק מהשאלות ששאלו אותי, להבהיר נקודות שבלבלו חלק מהאנשים ולהרחיב על חלק מהרעיונות שהוצגו בהרצאה.

כדי להבין את הבלוג פוסט הזה אתם צריכים להכיר את ההרצאה עצמה, המארגנים האדיבים של הכנס העלו את [ההרצאה במלואה בערוץ ה-Youtube שלהם](https://youtu.be/wxMQJ3vXngg), אתם מוזמנים לראות אותה שם :)  
בנוסף אתם מוזמנים לעבור על [המצגת שלי](https://docs.google.com/presentation/d/1QP9b4ywiy1CL_9DU-WOqo2rGDdN3GsB5Wu-hEX2_N6w/edit?usp=drivesdk) בעצמכם ובקצב שלכם, בלי קשר להרצאה עצמה.

## שאלות ותשובות

1. **מה המודל שלכם מוציא כפלט?**  
   בעת אימון למודל יש ראש קלאסיפיקציה, כלומר הפלט שלו הוא N וקטורים של לוג'יטים בגודל של כמות ה-class-ים (כמות הדוברים ב-train-set, במקרה שלנו 856).  
   בעת inference אנחנו לא משתמשים בראש הקלאסיפיקציה, לכן במקום לקבל N וקטורים של לוג'יטים אנחנו מקבלים N וקטורים של Embeddings (במקרה שלנו 256 מימדים).

2. **מה המודל בכלל לומד אם "לייק" לא מייחד את הקובץ? מה ה-supervision פה?**  
   המודל לומד לייצר לכל קובץ סט Embeddings שייצג את ה"לייקים" שתויגו עליו.  
   כלומר - המודל לומד לייצר Embeddings דומים לקבצים עליהם יש את אותו ה"לייק", עצם זה שצריך להיות Embedding משותף זה ה-supervision.

3. **דיברת על קלסטור ושהוא לא גזיר, אבל יש דרכים להוציא משקולים גזירים מאלגוריתמי קלסטור, לא ניסיתם אותן?**  
   תשובה קצרה - לא ניסינו, זה לא היה נגיש מספיק והיו לנו אינטואיציות שזה לא יעבוד טוב.  
   בקצת יותר פירוט - כמו שפירטתי בהמשך בפוסט על [הסימולציה](#הסימולציה), היו לנו עדויות שמימד הזמן משמעותי מאוד, ואלגוריתם לומד יוכל לעשות הרבה שקלסטור שמתעלם ממימד הזמן לעולם לא יוכל. וקלסטור שמתייחס למימד הזמן זה תסבוך שלם משלו, בסקירת הספרות שלנו לא מצאנו משהו מתאים.

4. **איך בנויות שכבות המודול הממשקל שלכם?**  
   השתמשנו במימוש של torchaudio לבלוק ה-Encoder של WavLM, בגדול בלוק חמוד עם self-attention ו-positional-embeddings וכמובן הרבה היפרפרמטרים built-in.  
   אין שום דבר מתוחכם בחלק הליבתי. זה Transformer.  
   אבל עשינו כמה דברים מעניינים מסביב, ראשית השתמשנו בשתי שכבות קונבולוציה כדי להוריד את כמות המימדים בערוצים פי 12 ובזמן פי 15, זה חסך המון VRAM וכמעט לא שינה ביצועים, אפילו הקל על האימון קצת ושיפר (לפחות האפוקים הראשונים).  
   אז ביציאה ניסינו לעשות קונבולוציה כדי להחזיר את מימד הזמן שהוקטן, בסוף הכי טוב היה לשכפל את המספרים 15 פעמים (repeat interleave), קונבולוציות גרעו.

5.

## העמקה והעשרה

פה בחרתי כמה נקודות ספציפיות שאהבתי במיוחד מהמחקר שלנו אבל לא היה לי זמן לפרט עליהן בהרצאה.  
אם אתם מחפשים להעשיר את הבנתכם באופי המחקר שניהלנו ואיך הגענו לחידושים שלנו - זה האזור בשבילכם :)

### הסימולציה

לפני שהתחלנו לעבוד עם DATA אמיתי התחלנו עם השאלה - מה היתרונות של אלגוריתם דיאריזציה לומד על פני קלסטור?  
חוץ מהיותו גזיר ולא מהונדס הייתה לנו נקודה אחת ייחודית - קלסטור מתעלם ממימד הזמן.

הנה דוגמא שתמחיש למה מימד הזמן הוא מהותי:

{::nomarkdown}
{% assign jupyter_path = 'assets/jupyter/he-il/weighter/simulation/stereo_envelope.ipynb' | relative_url %}
{% jupyter_notebook jupyter_path %}
{:/nomarkdown}

זו שיחת דוגמה מה-Dataset הידוע CALLHOME, זו שיחת טלפון טיפוסית בין בני משפחה.  
על גבי הספקטרוגרמה מוצג ה-envelope של כל ערוץ.  
בואו ננסה לעשות מה שדיאריזציה עושה - ננסה להבין בכל רגע מי מהערוצים מדבר:

{::nomarkdown}
{% assign jupyter_path = 'assets/jupyter/he-il/weighter/simulation/loud_channel.ipynb' | relative_url %}
{% jupyter_notebook jupyter_path %}
{:/nomarkdown}

הגרף הראשון שמעל מציג חישוב מאוד טריוויאלי לערוץ המדבר - היכן שה-envelope חזק יותר.  
אבל ניתן לראות שה-Real נראה מאוד שונה מ-Pure random, אז מה שונה?

שימו לב שהחלפת ערוץ היא דבר פחות נפוץ ב-Real, ב-Pure random כל frame לערוץ יש 50% להתחלף, בעוד ב-Real הסיכויים הרבה יותר נמוכים, כלומר ב-Real יש משמעות למימד הזמן.

דרך אחת למדל אקראיות שמתייחסת למימד הזמן היא Random walk, אנחנו השתמשנו בחישוב פשוט שיוצר Random walk שתחום בין 0 ל-1 כפי שניתן לראות בגרף השני.  
בגרף השלישי אנחנו משתמשים ב-Random walk כדי לבחור ערוץ באקראיות שתלויה בזמן, ניתן לראות ששני הגרפים נראים יותר דומים.

על בסיס הרעיון הזה יצרנו סימלציה של וקטורים שמתחלפים בתלות בזמן, ראינו שמודל לומד מסוגל להפריד את הוקטורים עם רעש גדול פי 4 ממה שקלסטור שמתעלם מזמן הצליח.

### ה-Confidence

כשהתחלנו את הפרויקט תהינו כיצד נוכל לגרום למודל להוציא פחות מ-N וקטורים באופן נלמד, חשבנו על הגישה של DETR שיצרו את ה-class ה-no-class, שאומר שזה לא אובייקט אמיתי.  
אנחנו היינו צריכים להתמודד עם הבעיה שבעת ריצה לא יהיה לנו Logits אלא Embeddings, לכן לא יכולנו לקחת את אותה הגישה.

ב-DETR גישת האימון כן דומה למה שהשתמשנו בסוף, רק שאנחנו החלטנו להפריד את הפלטים, פלט אחד של המודל יהיה המשקולים ופלט שני יהיה ה-Confidence-ים.  
למשל אם N=3, היינו אומרים למודל להוציא 6 מימדים, השלושה הראשונים מנורמלים לאורך זמן הם המשקולים, והממוצעים על הזמן של שלושת האחרונים הם ה-Confidence-ים.

נקרא לפלט של המשקולים X, ולפלט של ה-Confidence-ים Y.

ניסינו את זה, אבל ראינו תופעה מוזרה, נראה שה-confidence לא עבד ממש טוב, מאחר ועשינו ממוצע גלובלי הכרחנו בעצם כל token להסתכל על קונטקס גלובלי ככל שניתן כדי להבין לכל אחד מהמשקולים אם הוא אמיתי גם אם הוא יהיה 0 באותה נקודת זמן, כלומר זה בכלל דובר אחר.

מה שהחלטנו לעשות זה לחשב את ה-Confidence לא כממוצע של Y, אלא ממוצע ממושקל של Y על בסיס X.  
הרציונל שלנו היה שככה ה-token-ים של כל רגע בזמן יוכלו להתמקד ברגע הנוכחי והאם זה דובר אמיתי בלי להתחשב בהכרח בקונטקסט הגלובלי.  
הגישה הזו הוכיחה את העצמה עם שיפור משמעותי.

בשלב הזה היינו די מרוצים, אבל כשהסתכלנו על X ו-Y דבר אחד בלט לנו מאוד - הם היו מאוד דומים.  
ברמה שאמרנו - למה יש Y בכלל? אם הם זהים, פשוט נשים את X במקום Y.  
כשעשינו את זה - זה עבד אפילו טוב יותר מקודם.  
אבל אז הגענו להגדרה ממש מוזרה, ה-confidence שלנו הוא X ממושקל לפי X. מה?!

האינטואיציה שלנו לזה היא כזאת, זה סוג של ממוצע שמניח שככל שהערך יותר גדול הוא יותר חשוב.  
0 זה לא חשוב בכלל, 100 חשוב פי שניים מ-50.  
דוגמה למקרה בו חישוב כזה נחוץ יהיה למשל בקורונה, כשניסו להעריך עבור מאומת טיפוסי בסביבת כמה אנשים הוא היה.  
נניח שהוא יכל להדביק את הכל האנשים שהוא פגש בכל התקהלות בה הוא נכח, אם זו התקהלות של 100 אנשים הוא יכל להדביק 100, אם זו התקהלות של 200 אנשים הוא יכל להדביק 200 אנשים.  
אבל מה הסבירות שלו להיות נוכח בהתקהלות של 100 אנשים ביחס ל-200 אנשים?  
התשובה היא שפי שניים יותר סביר שהוא היה בהתקהלות של 200 אנשים מאשר 100 אנשים.  
אם נספור את כל ההתקהלויות ואת הסבירות של המאומת להיות בכל אחת מהן ונכפיל בכמות האנשים בכל התקהלות, ונקראה להתפלגות הכמויות X - נקבל בדיוק X ממושקל לפי X.

במקרה שלנו אנחנו מניחים שאם המשקול היה 0 במקום מסוים זה לא אומר הרבה על האדם הזה - כי סביר שהוא לא דיבר שם בכלל.  
מנגד אם הוא 1 זה אומר המון - כי כמעט בטוח שהוא היה שם.  
אם המודל לא בטוח בעצמו, הוא יוציא מספרים יותר נמוכים בלי לשנות את המשקול.

למעשה, ממש כמו סכום הערכים שנעלם אחרי שמנרמלים התפלגות ל-1 כדי ליצור משקולים, גם האינפורמציה של ה-Confidence היא בלתי תלויה במשקולים, כלומר המודל יכול לשנות כל אחד מהם מבלי להשפיע על השני.

### הנוסחה של wBCE

ה-wBCE הוא תוצאה מאוד נחמדה, נוסחה מאוד פשוטה אבל לא מובנת מאליה שמשפרת תוצאות ומשמרת תכונות חשובות של BCE.

אסביר את הפיתוח שלה כעת.

התחלנו עם השאלה - האם אנחנו יכולים להחליף את החלק של

###
