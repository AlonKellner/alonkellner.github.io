<!DOCTYPE html> <html lang="en-us"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta name="google-site-verification" content="ip2nVO5A9P6ENSeT_F_rRw5m68bYqr5WEgXyPasJid8"> <meta http-equiv="Permissions-Policy" content="interest-cohort=()"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> A Deep Dive into my "Weighter" talk in DefenseML | Alon Kellner </title> <meta name="author" content="Alon Kellner"> <meta name="description" content="An in depth explanation of a fascinating research effort called " weighter which i presented on mdli defenseml conference.> <meta name="keywords" content="alon, kellner, kellnerz, academic, portfolio, website, software, engineer, data-science, speech, waloviz, poetry, stories, chfsto, cv, blog, אלון, קלנר, קלנרז"> <meta property="og:site_name" content="Alon Kellner"> <meta property="og:type" content="article"> <meta property="og:title" content="Alon Kellner | A Deep Dive into my " weighter talk in defenseml> <meta property="og:url" content="https://alonkellner.com/blog/2024/weighter-presentation/"> <meta property="og:description" content="An in depth explanation of a fascinating research effort called " weighter which i presented on mdli defenseml conference.> <meta property="og:image" content="https://alonkellner.com/assets/img/headshot.jpeg"> <meta property="og:locale" content="en-us"> <meta name="twitter:card" content="summary"> <meta name="twitter:title" content="A Deep Dive into my " weighter talk in defenseml> <meta name="twitter:description" content="An in depth explanation of a fascinating research effort called " weighter which i presented on mdli defenseml conference.> <meta name="twitter:image" content="https://alonkellner.com/assets/img/headshot.jpeg"> <meta name="twitter:site" content="@KellnerAlon"> <meta name="twitter:creator" content="@KellnerAlon"> <script type="application/ld+json">
    {
        "author":
        {
            "@type": "Person",
            "name": "Alon Kellner"
        },
        "url": "https://alonkellner.com/blog/2024/weighter-presentation/",
        "@type": "BlogPosting",
        "description": "An in depth explanation of a fascinating research effort called "Weighter" which I presented on MDLI's DefenseML conference.",
        "headline": "A Deep Dive into my "Weighter" talk in DefenseML",
        
        "sameAs": ["https://github.com/AlonKellner", "https://www.linkedin.com/in/alonkellner", "https://x.com/KellnerAlon", "https://medium.com/@alonkellner"],
        
        "name": "Alon Kellner",
        "@context": "https://schema.org"
    }
  </script> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?e7cc02b035b1e757441f44e29b31a437"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?dadeb9c5d1fd12bc8d37475657446863"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="icon" href="/favicon.ico" sizes="32x32"> <link rel="icon" href="/favicon.svg" sizes="any" type="image/svg+xml"> <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"> <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png"> <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"> <link rel="manifest" href="/site.webmanifest"> <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"> <meta name="msapplication-TileColor" content="#da532c"> <meta name="theme-color" content="#ffffff"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://alonkellner.com/blog/2024/weighter-presentation/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold"> Alon </span> Kellner </a> <button class="navbar-toggler collapsed style=" margin-left: auto white-space: nowrap type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav flex-nowrap" style="margin-left: auto; white-space: nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/github/">GitHub </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/drawer/">Drawer </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false"> <span class="fi fi-us"></span> </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item" href="/he-il/blog/2024/weighter-presentation/"> <span class="fi fi-il"></span> </a> </div> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title" id="a-deep-dive-into-my-weighter-talk-in-defenseml"> A Deep Dive into my "Weighter" talk in DefenseML </h1> <p class="post-meta"> Created in November 06, 2024 </p> <p class="post-tags"> <a href="/blog/2024"> <i class="fa-solid fa-calendar fa-sm"></i> 2024 </a>   ·   <a href="/blog/tag/research"> <i class="fa-solid fa-hashtag fa-sm"></i> research</a>   ·   <a href="/blog/category/professional"> <i class="fa-solid fa-tag fa-sm"></i> professional</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p><br></p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/defenseml/en-us/01-480.webp 480w,/assets/img/defenseml/en-us/01-800.webp 800w,/assets/img/defenseml/en-us/01-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/defenseml/en-us/01.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Opening Slide" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Watch <a href="https://machinelearning.co.il/lp-events/defenseml/" rel="external nofollow noopener" target="_blank">the recording of me presenting!</a> You may also view <a href="https://docs.google.com/presentation/d/173AjB0vz8pdrKIiAR8JdxvhF1KGvq_SESwpL-LW-G78/edit?usp=sharing" rel="external nofollow noopener" target="_blank">the original presentation</a> :) </div> <p>The DefenseML conference was fascinating and meaningful. I had the pleasure of speaking alongside talented speakers and talented organizers who invested in a conference of a very high standard.</p> <p>After the lecture, I got to talk to some of the conference guests. I received many compliments, but there were also criticisms and difficulties.<br> The first criticism I was told was that the LinkedIn slide was only at the beginning of the presentation - before they knew I was worth anything.<br> Fortunately, this is a criticism that was easy to correct. The more general criticism that was not explicitly stated but was clear to me - is that it is difficult to understand from the lecture how things really work.</p> <p>This is a criticism that I expected, in 20 minutes it is impossible to summarize all the details of a complete and extensive research effort. I tried to give a taste, intuitions, directions, but I could not provide understanding.<br> In this post, I will try to answer some of the questions I was asked, clarify points that confused some people, and expand on some of the ideas presented in the lecture.</p> <p>To understand this blog post you need to be familiar with the lecture itself, the kind organizers of the conference uploaded <a href="https://youtu.be/wxMQJ3vXngg" rel="external nofollow noopener" target="_blank">the full lecture on their Youtube channel</a>, you are welcome to watch it there :)<br> In addition, you are welcome to go through <a href="https://docs.google.com/presentation/d/173AjB0vz8pdrKIiAR8JdxvhF1KGvq_SESwpL-LW-G78/edit?usp=sharing" rel="external nofollow noopener" target="_blank">my presentation</a> yourself and at your own pace, regardless of the recording itself.</p> <p>There are 2 parts in this blog post, the first is <a href="#q--a">Q &amp; A</a> where I’ll answer some of the questions I was asked after the lecture, most of them are clarifications about the details of our research and method.<br> The second part is <a href="#deep-dive--enrichment">Deep dive &amp; Enrichment</a> will expand on subjects which I didn’t have the time to get into in the lecture.</p> <p>Let’s start :)</p> <h2 id="q--a">Q &amp; A</h2> <ol> <li> <p><strong>What does your model output?</strong><br> During training, the model has a classification head, meaning its output is N vectors of logits the size of the number of classes (the number of speakers in the train-set, in our case 856).<br> During inference, we do not use the classification head, so instead of getting N vectors of logits we get N vectors of Embeddings (in our case 256 dimensions).</p> </li> <li> <p><strong>What does the model even learn if a “like” does not distinguish the file? What is the supervision here?</strong><br> The model learns to produce for each file a set of Embeddings, a subset of those Embeddings should represent the “likes” that were tagged on the file.<br> In other words, the model learns to produce Embeddings that are similar to files that have the same “like”, the very fact that there should be some common Embeddings is the supervision.</p> </li> <li> <p><strong>You talked about clustering and that it is not differentiable, but there are ways to extract differentiable weightings from clustering algorithms, have you tried them?</strong><br> Short answer - we didn’t try, it wasn’t accessible enough and we had intuitions that it wouldn’t work well.<br> In a little more detail - as I elaborate later in the post about <a href="#the-simulation">The Simulation</a>, we had evidence that the time dimension is very significant, and a learning algorithm could do a lot that a clustering algorithm that ignores the time dimension could never do.<br> (P.S: A clustering that takes into account the time dimension is a whole complication of its own, in our literature review we didn’t find anything suitable).</p> </li> <li> <p><strong>How ​​are the layers of your “Weighter” module structured?</strong><br> We used torchaudio’s implementation of the WavLM Encoder block, basically a cute block with self-attention and positional-embeddings and of course lots of built-in hyperparameters.<br> There is nothing sophisticated in the core part. It’s a Transformer.<br> But we did some interesting things around it, first we used two convolution layers to reduce the number of dimensions in channels by a factor of 12 and in time by a factor of 15, this saved a lot of VRAM and almost did not change performance, it even made training a little easier and improved performance (at least during the first few epochs).<br> So at the output we tried to do a convolution to restore the reduced time dimension, in the end the best option was to duplicate the weightings 15 times (repeat interleave), convolutions were worse.</p> </li> </ol> <h2 id="deep-dive--enrichment">Deep dive &amp; Enrichment</h2> <p>Here I’ve chosen a few specific subjects from our research that I particularly liked but didn’t have time to go into detail about during the lecture.<br> If you’re looking to enrich your understanding of the nature of the research we conducted and how we arrived at our innovations – this section is for you :)</p> <h3 id="layers-from-torchaudio">Layers from <code class="language-plaintext highlighter-rouge">torchaudio</code> </h3> <p>We invested very little in the layers of the model; we didn’t try to create something very sophisticated. We wanted something accessible and effective with a lot of hyperparameters.<br> The typical approach nowadays would be to take a layer from some model in <code class="language-plaintext highlighter-rouge">transformers</code>, but we saw that there is a decent implementation of WavLM blocks in a library we were already using – <code class="language-plaintext highlighter-rouge">torchaudio</code>.</p> <p>Here’s our <code class="language-plaintext highlighter-rouge">import</code>:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="n">torchaudio.models.wav2vec2.components</span> <span class="kn">import</span> <span class="n">_get_wavlm_encoder</span><span class="p">,</span> <span class="n">FeatureProjection</span>
</code></pre></div></div> <p>The function <code class="language-plaintext highlighter-rouge">_get_wavlm_encoder</code> creates a Transformer block with built-in positional embeddings, etc. It takes a sequence of vectors and outputs a sequence of the same size with self-attention, exactly what we were looking for.</p> <p>The class <code class="language-plaintext highlighter-rouge">FeatureProjection</code> is just a simple transformation with layer-norm and dropout that needs to be applied before feeding the input into the encoder.</p> <p>This saved us the dependency on <code class="language-plaintext highlighter-rouge">transformers</code>, and maybe it can help you too :)</p> <h3 id="the-simulation">The Simulation</h3> <p>Before we started working with real data, we started by asking ourselves a question: what are the advantages of a diarization algorithm that learns over a clustering approach?<br> Apart from it being differentiable and not engineered, we had one unique advantage – clustering ignores the time dimension.</p> <p>Here’s an example that will illustrate why the time dimension is essential:</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/weighter/simulation/stereo_envelope.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>This is a sample conversation from the well-known CALLHOME dataset, a typical phone call between family members.<br> The envelope of each channel is displayed over the spectrogram.<br> Let’s try to do what diarization does – let’s try to determine which channel is speaking at any given moment:</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/weighter/simulation/loud_channel.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>The first graph above shows a very trivial calculation to determine the speaking channel - where the envelope is stronger.<br> But you can see that “Real” looks very different from “Pure random”, so what’s different?</p> <p>Note that channel switching is less common in “Real”, in “Pure random” each frame has a 50% chance of switching channels, while in “Real” the chances are much lower, meaning that in “Real” the time dimension has significance.</p> <p>One way to model randomness that takes the time dimension into account is a “Random walk”, we used a simple calculation that creates a “Random walk” bounded between 0 and 1, as shown in the second graph.<br> In the third graph we use the “Random walk” to randomly select a channel per frame with time-dependent randomness, and you can see that the two graphs look much more similar.</p> <p>Based on this idea, we created a simulation of vectors that switch depending on time, and we saw that a learning model is able to separate vectors with noise four times larger than what clustering, which ignores time, could achieve.</p> <h3 id="confidence">Confidence</h3> <p>Our definition of Confidence is non-trivial, as presented in this presentation, using the following formula:</p> \[C(\mathbf{X}) =\frac{\sum _{j=1}^{T} X_{j}^{2}}{\sum _{i=1}^{T} X_{i}}\] <p>Where C is the formula for calculating Confidence, and <strong>X</strong> is the output of the weighting layer, T is the length of the time dimension of <strong>X</strong>, and X_i is the value at time i out of T in the timeline, all X_i values ​​are between 0 and 1.</p> <p>To get to this, we went through a multi-step process. I will share the concepts we explored and how we progressed from one to another until we arrived at this formula.<br> I think this is a classic example of iterative research based on experience, and maybe it will inspire you :)</p> <p>When we started the project, we wondered how we could make the model output fewer than N vectors in a learnable way. We considered the DETR approach, which created a class called “no-class,” meaning it is not a real object.<br> We had to deal with the problem that, during inference, we would not have Logits but Embeddings, so we couldn’t apply the same approach as DETR.</p> <p>In DETR, the training approach is similar to what we ended up using. However, initially, we decided to separate the outputs. One output of the model would be the weightings, and the second output would be the confidences.<br> For example, if N = 3, we would design the model to output 6 dimensions: the first three, normalized over time, represent the weightings, and the averages over time of the last three represent the confidences.</p> <p>We call the output of the weightings <strong>X</strong>, and the output of the confidences <strong>Y</strong>:</p> <p>\(C(\mathbf{Y}) =\frac{\sum _{j=1}^{T} Y_{j}}{T}\)</p> <p>\(W_{j}(\mathbf{X}) =\frac{X_{j}}{\sum _{i=1}^{T} X_{i}}\)</p> <p>Note that to make Y a confidence, we averaged it since it should be a single number, while to get the weightings, we normalized X by its sum, so that it sums to one, as is appropriate for the definition of weightings.</p> <p>We tried this, but we observed a strange phenomenon. It seemed that the confidence didn’t work very well. Since we did a global average, we basically forced each token to look at as much global context as possible in order to understand for each of the weightings whether it is real, even if it is 0 at that moment, meaning it is a completely different speaker.</p> <p>What we decided to do was calculate the Confidence not as an average of Y, but as a weighted average of Y based on X:</p> <p>\(C(\mathbf{X}, \mathbf{Y}) = \sum _{j=1}^{T} Y_{j} \cdot W_{j}(\mathbf{X})\)</p> <p>\(W_{j}(\mathbf{X}) = \frac{X_{j}}{\sum _{i=1}^{T} X_{i}}\)</p> <p>Our rationale was that this way, the tokens at each moment in time could focus on the current moment and whether it was a real speaker, without necessarily considering the global context.<br> This approach showed significant improvement.</p> <p>At this point, we were quite satisfied. But when we looked at <strong>X</strong> and <strong>Y</strong>, one thing stood out to us – they were very similar.<br> At that level, we asked ourselves: why have <strong>Y</strong> at all? If they are the same, we can just replace <strong>Y</strong> with <strong>X</strong>:</p> <p>\(C(\mathbf{X}) = \sum _{j=1}^{T} X_{j} \cdot W_{j}(\mathbf{X})\)</p> <p>\(W_{j}(\mathbf{X}) = \frac{X_{j}}{\sum _{i=1}^{T} X_{i}}\)</p> <p>When we did this, it worked even better than before.<br> A simple development will show that this form is equivalent to the final formula we arrived at:</p> <p>\(C(\mathbf{X}) = \sum _{j=1}^{T} X_{j} \cdot W_{j}(\mathbf{X}) = \sum _{j=1}^{T} X_{j} \cdot \frac{X_{j}}{\sum _{i=1}^{T} X_{i}} = \frac{\sum _{j=1}^{T} X_{j}^{2}}{\sum _{i=1}^{T} X_{i}}\)</p> <p>But then we arrived at a very strange definition. Our confidence is <strong>X</strong> weighted by <strong>X</strong>. What?!</p> <p>Our intuition behind this is that it is a kind of average where the larger the value, the more important it is.<br> Zero is not important at all, while 100 is twice as important as 50.<br> An example of a case where such a calculation would be necessary is in the context of the coronavirus. When trying to estimate how many people a confirmed infected patient could have been around, for example, if it was at a gathering of 100 people, they could infect 100 people, and if it was at a gathering of 200 people, they could infect 200 people.<br> But what is the probability of them being at a gathering of 100 people versus 200 people?<br> The answer is that they are twice as likely to have been at a gathering of 200 people than a gathering of 100 people.<br> If we count all the gatherings, the probability of the confirmed person being at each one, and multiply by the number of people in each gathering, and call the distribution of quantities <strong>X</strong>, we get exactly <strong>X</strong> weighted by <strong>X</strong>.</p> <p>In our case, we assume that if the weight was 0 at a certain time, it doesn’t mean much about that person, because it’s likely they didn’t speak there at all.<br> On the other hand, if the weight is 1, it says a lot – because it’s almost certain they were there.<br> If the model is not confident, it will output lower numbers without changing the weightings.</p> <p>In fact, just as the magnitude is independent of the direction of a vector, the information of the confidence is also independent of the weightings, meaning the model can change each of them without affecting the other.</p> <p>This is a non-obvious solution, an elegant one, and also the best one we tested. That’s as good as they get in my opinion :)</p> <h3 id="the-wbce-formula">The wBCE Formula</h3> <p>\(wBCE(y,\hat{y})=-y⋅\ln(\hat{y})+\hat{y}\)</p> <p>wBCE is a very neat result - it’s a very simple formula, but not an obvious one, which improves results while maintaining important properties of BCE.</p> <p>I will now explain its development.</p> <p>First, let’s recall the definition of BCE:</p> <p>\(BCE(y,\hat{y})=-y⋅\ln(\hat{y})-(1-y)⋅\ln(1-\hat{y})\)</p> <p>In our development, we began with the question: can we replace the part that penalizes errors when y is 0 with something else that will maintain the minimum point of BCE in one dimension?</p> <p>\(wBCE(y,\hat{y})=-y⋅\ln(\hat{y})+f(y, \hat{y})\)</p> <p>\(min(wBCE(y,\hat{y}))=min(BCE(y,\hat{y}))\)</p> <p>I won’t elaborate on this here, but I’ll mention that the minimum of BCE is simply y:</p> <p>\(min(BCE(y,\hat{y}))=y\)</p> <p>\(min(wBCE(y,\hat{y}))=y\)</p> <p>Let’s try to understand the desired properties for f to satisfy this condition.</p> <p>\(\frac{d}{d\hat{y}} wBCE(y,\hat{y})=-\frac{y}{\hat{y}}+\frac{d}{d\hat{y}}f(y, \hat{y})\)</p> <p>We know that when y_hat = y, it is the minimum point, meaning the derivative equals 0:</p> <p>\(-\frac{y}{y}+\frac{d}{d\hat{y}}f(y, \hat{y})=0\)</p> <p>\(\frac{d}{d\hat{y}}f(y, \hat{y})=1\)</p> <p>(The case where y = 0 is important but will not be explained here, the desired properties remain)</p> <p>That is, the derivative of f when y_hat = y is 1.<br> Of course, there are infinitely many solutions to this problem, but we want a solution that is more moderate than ln, so a simple approach would be to aim for a linear formula like this:</p> <p>\(f(y, \hat{y})=m\hat{y}+n\)</p> <p>Based on what we already know, we can conclude that m must be equal to 1, and we can choose n without affecting the minimum point.</p> <p>The simplest solution would be:</p> <p>\(f(y, \hat{y})=\hat{y}\)</p> <p>If we substitute this back into the formula we started with, we get the final formula for wBCE:</p> <p>\(wBCE(y,\hat{y})=-y⋅\ln(\hat{y})+f(y, \hat{y})=-y⋅\ln(\hat{y})+\hat{y}\)</p> <p>To get more intuition about the differences, I’ll present some simple visualizations comparing BCE and wBCE:</p> <div class="jupyter-notebook" style="position: relative; width: 100%; margin: 0 auto;"> <div class="jupyter-notebook-iframe-container"> <iframe src="/assets/jupyter/weighter/wBCE.ipynb.html" style="position: absolute; top: 0; left: 0; border-style: none;" width="100%" height="100%" onload="this.parentElement.style.paddingBottom = (this.contentWindow.document.documentElement.scrollHeight + 10) + 'px'"></iframe> </div> </div> <p>In the first set of graphs, you can see that the minimum point for both BCE and wBCE appears to align, exactly when y_hat = y.</p> <p>In the second set of graphs, I numerically compute the derivatives (gradients) of both and show them. It is clear that both derivatives cross 0 at the same point, or in other words, the sign of the gradient of BCE always matches the sign of the gradient of wBCE.<br> Additionally, you can see that BCE contains both large positive and negative gradients near the asymptotes, whereas wBCE contains only one asymptote near 0. This means wBCE has large negative gradients but its positive gradients are at most 1.</p> <p>As can be understood, wBCE does its job; it bounds the gradient size possible during a labeling error when y = 0.</p> <p>The improvement from BCE to wBCE is not dramatic, but it was necessary for us to meet our objectives.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/lessons-from-launch/">Lessons from Launching an Open-Source</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/portfolio-deeper/">Deeper into the Portfolio</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/portfolio-start/">My Portfolio Year Starts</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/waloviz-out/">WaloViz is Out!</a> </li> <div id="giscus_thread" style="max-width: 900px; margin: 0 auto;"> <br> <script>let giscusTheme=determineComputedTheme(),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"AlonKellner/alonkellner.github.io","data-repo-id":"R_kgDOMCOI5w","data-category":"Comments","data-category-id":"DIC_kwDOMCOI584CfsPW","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"en",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Alon Kellner. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/george-gca/multi-language-al-folio" rel="external nofollow noopener" target="_blank">multi-language-al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Last updated: Nov 21, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?74f6d60779ce0327683c2e7dbb3e4d87"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js" integrity="sha256-rjmgmaB99riUNcdlrDtcAiwtLIojSxNyUFdl+Qh+rB4=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-FQE9BVM4NQ"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-FQE9BVM4NQ");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?eaf77346e117baa09987a278a117b9a7"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?1e857a67d06dc1beccff2d96fe528619"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"> <script>let theme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===theme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"About",section:"Navigation menu",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"Blog",description:"What have I been up to? I publish all of it here first :)",section:"Navigation menu",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"Publications",description:"Currently I have no publications. Hopefully that will change soon.",section:"Navigation menu",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"Projects",description:"My projects, typically technological with a corresponding open-source GitHub repository.",section:"Navigation menu",handler:()=>{window.location.href="/projects/"}},{id:"nav-github",title:"GitHub",description:"My github reputation",section:"Navigation menu",handler:()=>{window.location.href="/github/"}},{id:"nav-cv",title:"CV",description:"Want to know what I&#39;ve been up to? My CV sums it up well, If you want to know more - read my blog!",section:"Navigation menu",handler:()=>{window.location.href="/cv/"}},{id:"nav-teaching",title:"Teaching",description:"TeachingLearning materials that I created.",section:"Navigation menu",handler:()=>{window.location.href="/teaching/"}},{id:"nav-drawer",title:"Drawer",description:"My creative drawer. Most of my works are in Hebrew.",section:"Navigation menu",handler:()=>{window.location.href="/drawer/"}},{id:"post-a-deep-dive-into-my-quot-weighter-quot-talk-in-defenseml",title:"A Deep Dive into my &quot;Weighter&quot; talk in DefenseML",description:"An in depth explanation of a fascinating research effort called &quot;Weighter&quot; which I presented on MDLI&#39;s DefenseML conference.",section:"Posts",handler:()=>{window.location.href="/blog/2024/weighter-presentation/"}},{id:"post-lessons-from-launching-an-open-source",title:"Lessons from Launching an Open-Source",description:"Launching WaloViz taught me a lot, this post is about my experience, conclusions and plans.",section:"Posts",handler:()=>{window.location.href="/blog/2024/lessons-from-launch/"}},{id:"post-waloviz-is-out",title:"WaloViz is Out!",description:"My newest open-source project, WaloViz",section:"Posts",handler:()=>{window.location.href="/blog/2024/waloviz-out/"}},{id:"post-deeper-into-the-portfolio",title:"Deeper into the Portfolio",description:"Deeper thoughts about the portfolio year and its meaning to me",section:"Posts",handler:()=>{window.location.href="/blog/2024/portfolio-deeper/"}},{id:"post-my-portfolio-year-starts",title:"My Portfolio Year Starts",description:"A Portfolio year, dedicated to achieving successful projects and publications",section:"Posts",handler:()=>{window.location.href="/blog/2024/portfolio-start/"}},{id:"drawer-first-assignment",title:"First Assignment",description:"A poem I wrote during my service, about responsibility, frustration, the &quot;Organization&quot; and doubt.",section:"",handler:()=>{window.location.href="/drawer/poem_2021-01-31_first_assignment/"}},{id:"drawer-beauty",title:"Beauty",description:"A poem I wrote during my service, about beauty, appreciation, potential and creation.",section:"",handler:()=>{window.location.href="/drawer/poem_2021-02-02_beauty/"}},{id:"drawer-first-met",title:"First Met",description:"A short story I wrote during my service, about youth, partnership, confidence and time-travels.",section:"",handler:()=>{window.location.href="/drawer/story_2021-02-08_first-met/"}},{id:"drawer-a-divine-error",title:"A Divine Error",description:"An episodical comedy about philosophy, the military, life and everything in between.",section:"",handler:()=>{window.location.href="/drawer/story_2021-02-10_a-divine-error_index/"}},{id:"drawer-a-divine-error-episode-1-straight-line",title:"A Divine Error, Episode 1: Straight Line",description:"An episodical comedy about philosophy, the military, life and everything in between.",section:"",handler:()=>{window.location.href="/drawer/story_2021-02-11_a-divine-error_ep1-straight-line/"}},{id:"drawer-a-divine-error-episode-2-standing-guard",title:"A Divine Error, Episode 2: Standing Guard",description:"An episodical comedy about philosophy, the military, life and everything in between.",section:"",handler:()=>{window.location.href="/drawer/story_2021-02-15_a-divine-error_ep2-standing-guard/"}},{id:"drawer-a-divine-error-episode-3-a-friend-39-s-help",title:"A Divine Error, Episode 3: A Friend&#39;s Help",description:"An episodical comedy about philosophy, the military, life and everything in between.",section:"",handler:()=>{window.location.href="/drawer/story_2021-02-28_a-divine-error_ep3-friends-help/"}},{id:"drawer-a-divine-error-episode-4-unknown",title:"A Divine Error, Episode 4: Unknown",description:"An episodical comedy about philosophy, the military, life and everything in between.",section:"",handler:()=>{window.location.href="/drawer/story_2021-03-23_a-divine-error_ep4-unknown/"}},{id:"drawer-a-divine-error-episode-5-the-zeroth-day",title:"A Divine Error, Episode 5: The Zeroth Day",description:"An episodical comedy about philosophy, the military, life and everything in between.",section:"",handler:()=>{window.location.href="/drawer/story_2021-03-24_a-divine-error_ep5-the-zeroth-day/"}},{id:"drawer-a-divine-error-episode-6-next-door",title:"A Divine Error, Episode 6: Next Door",description:"An episodical comedy about philosophy, the military, life and everything in between.",section:"",handler:()=>{window.location.href="/drawer/story_2021-03-25_a-divine-error_ep6-next-door/"}},{id:"drawer-a-divine-error-episode-7-comfort-zone",title:"A Divine Error, Episode 7: Comfort Zone",description:"An episodical comedy about philosophy, the military, life and everything in between.",section:"",handler:()=>{window.location.href="/drawer/story_2021-03-26_a-divine-error_ep7-comfort-zone/"}},{id:"drawer-\u05d8\u05e2\u05d5\u05ea-\u05d0\u05dc\u05d5\u05d4\u05d9\u05ea-\u05e4\u05e8\u05e7-8-\u05d0\u05d9\u05df-\u05d6\u05de\u05df",title:"\u05d8\u05e2\u05d5\u05ea \u05d0\u05dc\u05d5\u05d4\u05d9\u05ea, \u05e4\u05e8\u05e7 8: \u05d0\u05d9\u05df \u05d6\u05de\u05df",description:"\u05e1\u05d9\u05e4\u05d5\u05e8 \u05e7\u05d5\u05de\u05d3\u05d9\u05d4 \u05d1\u05d4\u05de\u05e9\u05db\u05d9\u05dd \u05e2\u05dc \u05e4\u05d9\u05dc\u05d5\u05e1\u05d5\u05e4\u05d9\u05d4, \u05e6\u05d1\u05d0, \u05d4\u05d7\u05d9\u05d9\u05dd \u05d5\u05de\u05d4 \u05e9\u05d1\u05d9\u05e0\u05d9\u05d4\u05dd.",section:"",handler:()=>{window.location.href="/drawer/story_2021-03-27_a-divine-error_ep8-no-time/"}},{id:"drawer-the-river-of-life",title:"The River of Life",description:"A very short story I wrote during my service, about life, ambition, ethics and history.",section:"",handler:()=>{window.location.href="/drawer/story_2021-06-06_river-of-life/"}},{id:"drawer-the-time-for-an-adventure",title:"The Time for an Adventure",description:"A very short story I wrote during my service, about curiosity, perspective, resolve and kindness.",section:"",handler:()=>{window.location.href="/drawer/story_2021-06-07_time-for-adventure/"}},{id:"drawer-comfort-in-darkness",title:"Comfort in Darkness",description:"A poem I wrote during my service, about ambition, compromise, comfort and self delusion.",section:"",handler:()=>{window.location.href="/drawer/poem_2021-08-25_comfort-in-darkness/"}},{id:"drawer-missing",title:"Missing",description:"A poem I wrote during my service, about thoughts, longing, expectations, self-contradiction and getting lost.",section:"",handler:()=>{window.location.href="/drawer/poem_2021-09-22_missing/"}},{id:"drawer-way-of-the-will",title:"Way of the Will",description:"A poem I wrote during my service, about resolve, freedom, wills and hubris.",section:"",handler:()=>{window.location.href="/drawer/poem_2022-06-19_way-of-the-will/"}},{id:"drawer-regrets",title:"Regrets",description:"A Sondheim inspired poem, about being lost, the confinements of the self, acceptance and regrets.",section:"",handler:()=>{window.location.href="/drawer/poem_2022-11-20_regrets/"}},{id:"drawer-the-ballad-of-olmo-amp-molinari",title:"The Ballad of Olmo &amp; Molinari",description:"A poem I wrote on a cycling trip in Italy.",section:"",handler:()=>{window.location.href="/drawer/poem_2023-10-04_olmo-and-molinari/"}},{id:"drawer-go-and-return",title:"Go and Return",description:"A poem I wrote on my way back from Italy to Israel, between the 7th and 9th of October.",section:"",handler:()=>{window.location.href="/drawer/poem_2023-10-07_go-and-return/"}},{id:"drawer-life-at-sea",title:"Life at Sea",description:"A poem based on a strange dream, about the temporalness of an experience, the limits of the language and that which cannot be told.",section:"",handler:()=>{window.location.href="/drawer/poem_2024-06-13_life-at-sea/"}},{id:"drawer-three-flies",title:"Three Flies",description:"A poem with a twist on fears, about flies, humans, stories and horror.",section:"",handler:()=>{window.location.href="/drawer/poem_2024-06-24_three-flies/"}},{id:"drawer-a-million-words",title:"A Million Words",description:"A song about language, creation, sharing and a treasure made of words",section:"",handler:()=>{window.location.href="/drawer/poem_2024-10-14_a-million-words/"}},{id:"drawer-i-39-ll-say-anything",title:"I&#39;ll Say Anything",description:"A poem about a man in a grave, pondering about his life and what he took with him to that grave",section:"",handler:()=>{window.location.href="/drawer/poem_2024-10-15_ill-say-anything/"}},{id:"drawer-bystander",title:"Bystander",description:"A short story about valuing life, points of view, communal hive mind and smiles.",section:"",handler:()=>{window.location.href="/drawer/story_2024-10-20_bystander/"}},{id:"news-my-portfolio-year-starts-now-wish-me-luck",title:"My Portfolio Year starts NOW! Wish me luck :)",description:"",section:"News"},{id:"posts-my-portfolio-year-starts",title:"My Portfolio Year Starts",description:"A Portfolio year, dedicated to achieving successful projects and publications",section:"Posts",handler:()=>{window.location.href="/blog/2024/portfolio-start/"}},{id:"posts-deeper-into-the-portfolio",title:"Deeper into the Portfolio",description:"Deeper thoughts about the portfolio year and its meaning to me",section:"Posts",handler:()=>{window.location.href="/blog/2024/portfolio-deeper/"}},{id:"posts-waloviz-is-out",title:"WaloViz is Out!",description:"My newest open-source project, WaloViz",section:"Posts",handler:()=>{window.location.href="/blog/2024/waloviz-out/"}},{id:"posts-lessons-from-launching-an-open-source",title:"Lessons from Launching an Open-Source",description:"Launching WaloViz taught me a lot, this post is about my experience, conclusions and plans.",section:"Posts",handler:()=>{window.location.href="/blog/2024/lessons-from-launch/"}},{id:"posts-a-deep-dive-into-my-quot-weighter-quot-talk-in-defenseml",title:"A Deep Dive into my &quot;Weighter&quot; talk in DefenseML",description:"An in depth explanation of a fascinating research effort called &quot;Weighter&quot; which I presented on MDLI&#39;s DefenseML conference.",section:"Posts",handler:()=>{window.location.href="/blog/2024/weighter-presentation/"}},{id:"projects-waloviz",title:"WaloViz",description:"An open-source python package of an interactive audio player with a spectrogram built-in.",section:"Projects",handler:()=>{window.location.href="/projects/open-source_2024-07-25_waloviz/"}},{id:"socials-email",title:"Send an email",section:"Socials",handler:()=>{window.open("mailto:%6D%65@%61%6C%6F%6E%6B%65%6C%6C%6E%65%72.%63%6F%6D","_blank")}},{id:"socials-github",title:"GitHub",section:"Socials",handler:()=>{window.open("https://github.com/AlonKellner","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/alonkellner","_blank")}},{id:"socials-x",title:"X",description:"Twitter",section:"Socials",handler:()=>{window.open("https://x.com/KellnerAlon","_blank")}},{id:"socials-medium",title:"Medium",section:"Socials",handler:()=>{window.open("https://medium.com/@alonkellner","_blank")}},{id:"lang-he-il",title:"he-il",section:"Languages",handler:()=>{window.location.href="/he-il/blog/2024/weighter-presentation/"}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js"></script> </ninja-keys> </body> </html>